{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3548fe4a952ca65f",
   "metadata": {},
   "source": [
    "## LangChain chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T06:54:53.597821Z",
     "start_time": "2025-10-06T06:54:52.017991Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd970036ab362bbd",
   "metadata": {},
   "source": [
    "### Prosty chain: prompt → model → wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d97fe610b0504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:01:09.135841Z",
     "start_time": "2025-10-06T07:00:47.297520Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"jesteś ekspertem programowania w Pythonie i geniuszem w dziedzinie AI.\"),\n",
    "    (\"user\", \"napisz kod {topic}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'AGI'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9889063b3f8268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:01:24.319921Z",
     "start_time": "2025-10-06T07:01:24.316641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzenie prawdziwej sztucznej inteligencji ogólnej (AGI) to niezwykle złożone zadanie, które wykracza poza możliwości obecnych technologii i narzędzi. AGI odnosi się do systemów AI, które mogą rozumieć, uczyć się i stosować wiedzę w różnych dziedzinach, podobnie jak człowiek. Obecnie nie istnieje żaden kod, który mógłby stworzyć AGI, ponieważ wymagałoby to zaawansowanego zrozumienia świadomości, uczenia się, rozumienia kontekstu i wielu innych aspektów, które są wciąż badane.\n",
      "\n",
      "Jednak mogę pokazać prosty przykład, jak można zbudować system AI, który uczy się na podstawie danych, używając Pythona i popularnych bibliotek, takich jak TensorFlow lub PyTorch. Oto przykład prostego modelu uczenia maszynowego, który klasyfikuje dane:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "# Wczytaj dane\n",
      "data = load_iris()\n",
      "X = data.data\n",
      "y = data.target\n",
      "\n",
      "# Podziel dane na zestawy treningowe i testowe\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Normalizacja danych\n",
      "scaler = StandardScaler()\n",
      "X_train = scaler.fit_transform(X_train)\n",
      "X_test = scaler.transform(X_test)\n",
      "\n",
      "# Zbuduj model\n",
      "model = tf.keras.Sequential([\n",
      "    tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
      "    tf.keras.layers.Dense(10, activation='relu'),\n",
      "    tf.keras.layers.Dense(3, activation='softmax')  # 3 klasy w zbiorze Iris\n",
      "])\n",
      "\n",
      "# Kompilacja modelu\n",
      "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Trening modelu\n",
      "model.fit(X_train, y_train, epochs=50)\n",
      "\n",
      "# Ocena modelu\n",
      "loss, accuracy = model.evaluate(X_test, y_test)\n",
      "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
      "```\n",
      "\n",
      "Ten kod tworzy prosty model sieci neuronowej do klasyfikacji danych z zestawu Iris. Chociaż to nie jest AGI, to pokazuje, jak można używać Pythona do budowy systemów AI, które uczą się na podstawie danych. \n",
      "\n",
      "Prawdziwe AGI wymagałoby znacznie bardziej zaawansowanych algorytmów, architektur i podejść, które są wciąż w fazie badań.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac72131d772ec2",
   "metadata": {},
   "source": [
    "### Sequential chain: dwa modele w sekwencji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92240f604a750d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:04:37.608189Z",
     "start_time": "2025-10-06T07:04:33.692116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain permet de créer des applications d'IA en intégrant des modèles, des invites et des outils dans des processus organisés.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 1) Chain: streszczenie (wejście: {tekst} → wyjście: str)\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Streść poniższy tekst w 1–2 zdaniach po polsku.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2) Adapter: zamień str → {\"tekst\": str}, żeby podać do następnego promptu\n",
    "to_dict = RunnableLambda(lambda s: {\"tekst\": s})\n",
    "\n",
    "# 3) Chain: tłumaczenie streszczenia na francuski (wejście: {tekst} → wyjście: str)\n",
    "translate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Przetłumacz tekst na język francuski.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sequential_chain = summary_chain | to_dict | translate_chain\n",
    "input_text = \"LangChain umożliwia tworzenie aplikacji AI poprzez łączenie modeli, promptów i narzędzi w spójne pipeline’y.\"\n",
    "\n",
    "final_translation = sequential_chain.invoke({\"tekst\": input_text})\n",
    "\n",
    "print(final_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256cc9e98cf0ddff",
   "metadata": {},
   "source": [
    "### Branching chain: jedna odpowiedź, dwa przetworzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "783d3e92e71467ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:06:33.689570Z",
     "start_time": "2025-10-06T07:06:29.839509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'Uczestnik kursu jest bardzo zadowolony i zdobył wiele wiedzy na temat LangChain.', 'sentiment': 'Ton wypowiedzi jest pozytywny i entuzjastyczny. Osoba wyraża zadowolenie z kursu oraz podkreśla, że zdobyła cenną wiedzę na temat LangChain.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Prompt do streszczenia\n",
    "prompt_summary = ChatPromptTemplate.from_template(\"Streść: {tekst}\")\n",
    "\n",
    "# Prompt do sentymentu\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(\"Określ ton wypowiedzi: {tekst}\")\n",
    "\n",
    "branch_chain = RunnableParallel(\n",
    "    summary=(prompt_summary | llm | StrOutputParser()),\n",
    "    sentiment=(prompt_sentiment | llm | StrOutputParser())\n",
    ")\n",
    "\n",
    "text = \"Jestem bardzo zadowolony z tego kursu, nauczyłem się dużo o LangChain!\"\n",
    "result = branch_chain.invoke({\"tekst\": text})\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
